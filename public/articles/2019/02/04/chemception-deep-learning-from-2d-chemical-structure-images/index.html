<!DOCTYPE html>
<html lang="en-us" dir="ltr" class="scroll-smooth" data-default-appearance="light"
  data-auto-appearance="true"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="en-us" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>Chemception: Deep Learning from 2D Chemical Structure Images &middot; Depth-First</title>
  <meta name="title" content="Chemception: Deep Learning from 2D Chemical Structure Images &middot; Depth-First" />
  
  <meta name="description" content="This deep learning method breaks the mold by training itself, not on abstract binary fingerprints, but on simple, human-recognizable images." />
  
  
  
  <link rel="canonical" href="http://localhost:1313/articles/2019/02/04/chemception-deep-learning-from-2d-chemical-structure-images/" />
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/css/main.bundle.min.e27868ab1485f7ed7b06b122b4980bd38b19526eb8f7de885181204d28f04a0c47e9c334eff19a06c0278eb2ff8415b983a5d0fb80fd6b5680c926457cc61c57.css"
    integrity="sha512-4nhoqxSF9&#43;17BrEitJgL04sZUm64996IUYEgTSjwSgxH6cM07/GaBsAnjrL/hBW5g6XQ&#43;4D9a1aAySZFfMYcVw==" />
  
  
  <script type="text/javascript" src="/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js"
    integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj&#43;e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
  
  
  
  
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.c178288131a2f1ad46910438db47ac5f7e1c48cf949e49f6dc3310c8ec9660e23fe505805eba4e2e73711335808500360d773a2b64322feb35df52856edca286.js"
    integrity="sha512-wXgogTGi8a1GkQQ420esX34cSM&#43;Unkn23DMQyOyWYOI/5QWAXrpOLnNxEzWAhQA2DXc6K2QyL&#43;s131KFbtyihg==" data-copy="" data-copied=""></script>
  
  
  
  <script src="/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js" integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S&#43;Yti0U7QtuZvQ=="></script>
  
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/articles/2019/02/04/chemception-deep-learning-from-2d-chemical-structure-images/">
  <meta property="og:site_name" content="Depth-First">
  <meta property="og:title" content="Chemception: Deep Learning from 2D Chemical Structure Images">
  <meta property="og:description" content="This deep learning method breaks the mold by training itself, not on abstract binary fingerprints, but on simple, human-recognizable images.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2019-02-04T19:30:00+00:00">
    <meta property="article:modified_time" content="2019-02-04T19:30:00+00:00">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Chemception: Deep Learning from 2D Chemical Structure Images">
  <meta name="twitter:description" content="This deep learning method breaks the mold by training itself, not on abstract binary fingerprints, but on simple, human-recognizable images.">

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "Chemception: Deep Learning from 2D Chemical Structure Images",
    "headline": "Chemception: Deep Learning from 2D Chemical Structure Images",
    
    "abstract": "This deep learning method breaks the mold by training itself, not on abstract binary fingerprints, but on simple, human-recognizable images.",
    "inLanguage": "en-us",
    "url" : "http:\/\/localhost:1313\/articles\/2019\/02\/04\/chemception-deep-learning-from-2d-chemical-structure-images\/",
    "author" : {
      "@type": "Person",
      "name": ""
    },
    "copyrightYear": "2019",
    "dateCreated": "2019-02-04T19:30:00\u002b00:00",
    "datePublished": "2019-02-04T19:30:00\u002b00:00",
    
    "dateModified": "2019-02-04T19:30:00\u002b00:00",
    
    
    
    "mainEntityOfPage": "true",
    "wordCount": "2457"
  }]
  </script>


  
  
  
  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>






















  
  



  
  
  <meta name="theme-color"/>
  
  
</head>
<body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a>
  </div>
  
  
  <div style="padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px"
    class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3">
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            
            <a href="/" class="text-base font-medium text-gray-500 hover:text-gray-900">Depth-First</a>
            

        </nav>
        <nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12">

            

            


            
            <button id="search-button" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            


            
            
            <div
                class="ltr:mr-14 rtl:ml-14 flex items-center">
                <button id="appearance-switcher" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400">
                    <div class="flex items-center justify-center dark:hidden">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                    </div>
                    <div class="items-center justify-center hidden dark:flex">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                    </div>
                </button>
            </div>
            

        </nav>
        <div class="flex md:hidden items-center space-x-5 md:ml-12 h-12">

            <span></span>

            


            
            <button id="search-button-mobile" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            
            <button id="appearance-switcher-mobile" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400" style="margin-right:5px">
                <div class="flex items-center justify-center dark:hidden">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                </div>
                <div class="items-center justify-center hidden dark:flex">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                </div>
            </button>
            

        </div>
    </div>
    <div class="-my-2 -mr-2 md:hidden">

        <label id="menu-button" class="block">
            

            </div>
        </label>
    </div>
</div>





  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      


<article>
  

  <header id="single_header" class="mt-5 max-w-prose">
    
    <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
      Chemception: Deep Learning from 2D Chemical Structure Images
    </h1>
    <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
      





  
  







  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2019-02-04T19:30:00&#43;00:00">February 4, 2019</time><span class="px-2 text-primary-500">&middot;</span><span>2457 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">12 mins</span>
  

  
  
</div>








    </div>

    
    
    
    
    

    

    
      
      
        
        
<div class="flex author">
  
  <div class="place-self-center">
    
    
    <div class="text-2xl sm:text-lg">
</div>
  </div>
</div>

      

      

      
      <div class="mb-5"></div>
      

    

  </header>
  
  <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
    
    

      <div class="min-w-0 min-h-0 max-w-fit">
        
        


        <div class="article-content max-w-prose mb-20">
          <p>Recent advances in machine learning techniques have yielded systems that meet or even exceed human pattern-recognition capability. These powerful techniques are now starting to be used for chemical structure-property prediction. This article highlights a new approach that, in a break with past systems, works in a way that will be immediately (perhaps uncannily) recognizable to many research chemists.</p>


<h1 class="relative group">Chemception 
    <div id="chemception" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#chemception" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p><a href="https://arxiv.org/abs/1706.06689" target="_blank">
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/images/posts/20190204/chemception.png" alt="Chemception" />
      <figcaption>Chemception</figcaption>
    </figure>
</a></p>
<p><a href="https://arxiv.org/abs/1706.06689" target="_blank">Chemception</a> is a deep convolutional neural network (CNN) that accepts 80x80-pixel 2D chemical structure images as input. It can be configured to produce binary classifications (&ldquo;active&rdquo; vs &ldquo;inactive&rdquo; predictions) or regressions (numerical predictions) as output. The original Chemception paper describes training and use on datasets drawn from three areas: <a href="https://tripod.nih.gov/tox21/challenge/about.jsp" target="_blank">a panel of vitro toxicity assays</a> (Tox21); <a href="https://wiki.nci.nih.gov/display/NCIDTPdata/AIDS&#43;Antiviral&#43;Screen&#43;Data" target="_blank">an in vitro anti-HIV assay</a>; and <a href="https://doi.org/10.1007/s10822-014-9747-x" target="_blank">hydration free energy</a> (FreeSolv).</p>
<p>Chemception&rsquo;s accuracy compared favorably with, and sometimes exceeded, existing machine learning and computational methods. However, those other methods required extensive involvement from trained subject-matter experts. Chemception, on the other hand, required only the transformation of chemical line notations (SMILES strings) into appropriately-encoded grayscale images.</p>
<p>Chemception demonstrates that a deep neural network trained on 2D structure images can make predictions that rival or even exceed those from systems driven by human-driven feature identification.</p>


<h1 class="relative group">Image Encoding 
    <div id="image-encoding" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#image-encoding" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>Grayscale 80x80-pixel images were created directly from SMILES strings using a pipeline of open source tools. Atoms were encoded as dots with a shade of gray proportional to atomic number. Bonds were were encoded as lines between atoms using a shade of grey proportional to the number 2. The remainder of the image was colored black (a value of zero).</p>
<p>The authors don&rsquo;t discuss whether or not bond order was encoded in any way. Indeed, the description seems to state that bond order was not considered at all. If true, this lack of chemical information makes the relatively high accuracy of Chemception&rsquo;s predictions all the more impressive.</p>
<p>Images were barely processed further before entering the Chemception pipeline. Noting the sparsity of information density (~90% of pixels were set to zero in any given image), various helpful transformations used in other image classification studies were not performed. Images were randomly rotated 180 degrees, but were otherwise used as-is. A subsequent study (see below) encoded additional chemical information using a four-channel model.</p>


<h1 class="relative group">Machine Learning vs. Machine Intelligence 
    <div id="machine-learning-vs-machine-intelligence" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#machine-learning-vs-machine-intelligence" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>The creators of Chemception identify two fundamentally different modes for machine-assisted chemistry research:</p>
<ol>
<li><strong>Machine Learning Approach.</strong> Molecular features are selected and encoded through human-developed algorithms. These features are then used to train an artificial structure-property prediction system.</li>
<li><strong>Machine Intelligence Approach.</strong> Molecular features are selected and encoded automatically during the training of a structure-property prediction system.</li>
</ol>
<p>The development of predictive models in chemistry has been dominated by the first approach. Chemists apply their deep domain knowledge to define those molecular features deemed important for predicting a molecular behavior. These features, usually in the form of &ldquo;molecular descriptors,&rdquo; are then used to train a model. The development of molecular descriptors (of which <a href="/articles/2019/01/11/extended-connectivity-fingerprints/">extended connectivity/circular fingerprints</a> are an example) has been ongoing area of research <a href="https://en.wikipedia.org/wiki/Wiener_index" target="_blank">since the 1940s</a> with <a href="http://www.moleculardescriptors.eu/books/books.htm" target="_blank">well over 3,000</a> having been described to date.</p>
<p>By accepting raw input in the form of 2D structure images, Chemception eliminates the need for the human subject matter expert during training. Considering the astonishing rate at which artificial pattern recognition has caught up to and exceeded human capability in areas like <a href="https://www.wired.com/2015/01/karpathy/" target="_blank">image recognition</a>, the economic and scientific implications of the Machine Intelligence Approach embodied by Chemception are provocative.</p>


<h1 class="relative group">Deep Neural Networks 
    <div id="deep-neural-networks" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#deep-neural-networks" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>Chemception is an example of an artificial neural network (ANN). Neural networks come in a variety of configurations, but all can be modeled as directed graphs in which nodes map to functions, inbound edges map to arguments, and outbound edges map to return values. A neural network is typically arranged into layers of nodes disconnected from each other but connected to nodes in adjacent layers. At a minimum, an ANN contains two layers: an &ldquo;input layer&rdquo; that directly receives test or training data; and an &ldquo;output layer&rdquo; producing a classification or regression output. Layers between input and output are known as &ldquo;hidden layers.&rdquo; By one <a href="https://stats.stackexchange.com/q/182734" target="_blank">widely-used definition</a>, an ANN containing two or more hidden layer is considered &ldquo;deep.&rdquo; Machine learning that uses a deep neural network is called &ldquo;deep learning.&rdquo;</p>
<!-- raw HTML omitted -->
<p>Chemical structure-property machine learning studies often use a kind of an ANN configuration known as a <em>multilayer perceptron</em> (MLP, aka &ldquo;vanilla&rdquo; neural network). An MLP is characterized by at least one hidden layer, the nodes of which connect to all of the nodes in adjacent layers, but which do not connect to each other. Excellent introductions to the structure and function of MLPs are available in the video series embedded above and in the free book <a href="http://neuralnetworksanddeeplearning.com" target="_blank"><em>Neural Networks and Deep Learning</em></a>. The image below, excerpted from the book, illustrates the organization of layers in an MLP.</p>
<p><a href="http://neuralnetworksanddeeplearning.com/chap1.html" target="_blank">
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/images/posts/20190204/multilayer-perceptron.png" alt="Multilayer Perceptron" />
      <figcaption>Multilayer Perceptron</figcaption>
    </figure>
</a></p>
<p>When applied to chemistry, MLPs typically accept binary fingerprints as input.</p>


<h1 class="relative group">Convolutional Neural Networks 
    <div id="convolutional-neural-networks" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#convolutional-neural-networks" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>Chemception uses a kind of augmented MLP known as a <em>convolutional neural network</em> (CNN). A CNN employs one or more convolutional layers immediately following the input layer. In contrast to the nodes in the hidden layer of an MLP, nodes in a convolutional layer only connect to a subset of the nodes in the preceding layer. A convolutional layer detects patterns in the input layer through the stepwise application of one or more &ldquo;filters&rdquo; during a sweeping &ldquo;convolve&rdquo; operation.</p>
<!-- raw HTML omitted -->
<p>CNNs have proven extremely adept at image recognition and for this reason are currently the subject of intense interest. One of the most successful designs (<a href="https://arxiv.org/abs/1602.07261" target="_blank">Inception</a>) was integrated into Chemception.</p>


<h1 class="relative group">Estimating Accuracy 
    <div id="estimating-accuracy" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#estimating-accuracy" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>Two of the predictions made by Chemception, HIV activity and toxicity, were binary classifications (molecules were marked as either &ldquo;active&rdquo; or &ldquo;inactive&rdquo;). The accuracy of such classifications can be estimated by measuring the area under the curve (AUC) of the Receiver Operator Characteristic (ROC) graph. This graph plots the false positive rate (a number in the range 0.0-1.0) on the x-axis and the true positive rate (a number in the range 0.0-1.0) on the y-axis for varying classification thresholds. AUC ranges from 0.0 (model only predicts false positives) to 1.0 (model only predicts true positives). The video below explains AUC in detail.</p>
<!-- raw HTML omitted -->
<p>For example, the Chemception paper reports AUC for several configurations of the neural network tested against the Tox21 dataset (below). This study revealed one network configuration (<code>Chemception_T3_F16</code>) that worked the best. Additionally, the comparable AUCs for Train, Validation, and Test modes suggests that little overfitting occurred.</p>
<p><a href="https://arxiv.org/abs/1706.06689" target="_blank">
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/images/posts/20190204/tox21-auc-table.png" alt="Tox21 AUC Table" />
      <figcaption>Tox21 AUC Table</figcaption>
    </figure>
</a></p>


<h1 class="relative group">Performance Benchmarks 
    <div id="performance-benchmarks" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#performance-benchmarks" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>Using ROC AUC, Chemception&rsquo;s performance was compared to that of a previously-reported multi-layer perceptron deep neural network (<a href="https://arxiv.org/abs/1703.00564" target="_blank">MoleculeNet</a>). In that study, <a href="/articles/2019/01/11/extended-connectivity-fingerprints/">extended connectivity fingerprints</a> were inputs. The prediction accuracies for both systems were comparable, as shown in the graph below.</p>
<p><a href="https://arxiv.org/abs/1706.06689" target="_blank">
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/images/posts/20190204/chemception-vs-mlp-dnn-tox21.png" alt="Chemception vs MLP DNN in Tox21" />
      <figcaption>Chemception vs MLP DNN in Tox21</figcaption>
    </figure>
</a></p>
<p>Even better results were obtained against the same MoleculeNet network using the HIV dataset (below).</p>
<p><a href="https://arxiv.org/abs/1706.06689" target="_blank">
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/images/posts/20190204/chemception-vs-moleculenet-hiv.png" alt="Chemception vs MLP DNN in HIV" />
      
    </figure>
</a></p>
<p>The Chemception paper notes two points that may account for the differences between the Tox21 and HIV studies. First, the Tox21 comparison represents a worst case for Chemception because MoleculeNet was operating in multi-task mode, giving it a theoretical advantage. (Recall that the Tox21 dataset is comprised of a panel of twelve assays.) The ideal comparison would have pitted MoleculeNet against Chemception in single-task mode, but single-task data were not reported in the MoleculeNet study. Second, the HIV dataset is larger than the Tox21 dataset. Larger datasets are expected to help Chemception given that it must synthesize all of its own chemical feature identifications.</p>
<p>Chemception&rsquo;s performance in regression against published techniques was also evaluated for the FreeSolv hydration free energy dataset. Here, two previous benchmarks were compared using root mean square (RMS) analysis: MoleculeNet and FEP (molecular dynamics simulation). The results show Chemception outperforming MoleculeNet, and approaching the performance of the molecular dynamics simulation.</p>
<p><a href="https://arxiv.org/abs/1706.06689" target="_blank">
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/images/posts/20190204/chemception-vs-moleculenet-and-fep.png" alt="Chemception vs MoleculeNet and FEP" />
      <figcaption>Chemception vs MoleculeNet and FEP</figcaption>
    </figure>
</a></p>


<h1 class="relative group">AugChemception 
    <div id="augchemception" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#augchemception" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>The most surprising result from the Chemception study was how little chemical information was needed to produce competitive predictions. This raises the question of whether more information-rich 2D structure images might perform better. To address this question, the Chemception team conducted a follow-up study in which a new system, <a href="https://arxiv.org/abs/1710.02238" target="_blank">AugChemception</a> was developed and tested.</p>
<p>Using up to four color channels, 2D structure images were augmented with four chemical information properties:</p>
<ul>
<li>bond order</li>
<li>partial charge</li>
<li>atom hybridization</li>
<li>valence</li>
</ul>
<p>These properties were encoded into four images channels in analogy with the standard <a href="https://en.wikipedia.org/wiki/CMYK_color_model" target="_blank">CMYK model</a>. Ten schema were developed to aid in understanding the minimum chemical information requirements for effective model training:</p>
<p><a href="https://arxiv.org/abs/1710.02238" target="_blank">
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/images/posts/20190204/schema.png" alt="Schema" />
      <figcaption>Schema</figcaption>
    </figure>
</a></p>
<p>For example, &ldquo;Std&rdquo; represents the encoding used in the original Chemception paper: atomic numbers were encoded as shaded dots using a normalized grayscale. Bonds were assigned the relative grayscale 2 (a convenient choice given the lack of helium-containing structures). &ldquo;RedA&rdquo; images contained the least structure information because only atom dots were rendered, and each with the same shade of gray. &ldquo;RedB&rdquo; extends RedA with bond lines of uniform grayscale value. &ldquo;EngA&rdquo; encodes structural properties over four color channels. The last three schemes represent controls designed to detect artifacts and overtraining. Although the AugChemception paper doesn&rsquo;t give good examples of what these images actually look like, a subsequent study, described below, does.</p>
<p>The &ldquo;engineered&rdquo; schema EngA, EngB, EngC, and EngD yielded clear increases in accuracy for all datasets tested. For example, against the Tox21 dataset, the engineered AugChemception images performed about 4% better in terms of ROC AUC compared to the grayscale &ldquo;Std&rdquo; Chemception scheme. Similar results were obtained against the HIV dataset.</p>
<p><a href="https://arxiv.org/abs/1710.02238" target="_blank">
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/images/posts/20190204/augchemception-tox21.png" alt="AugChemception Tox21" />
      <figcaption>AugChemception Tox21</figcaption>
    </figure>
</a></p>
<p>An apparent split in accuracy favoring EngA/EngD over EngB/EngC schemes against the hydration free energy dataset was noted. Although all four schemes outperformed the original Std Chemception grayscale scheme, EngA/EngD performed the best of all. The authors note:</p>
<blockquote>
<p>Upon further examination, both EngA and EngD had partial charge and hybridization information encoded, but EngB and EngC do not.</p>
</blockquote>
<p>Indeed, it can be seen from Table 2 that EngA/EngD encode <em>both</em> partial charge and hybridization. EngB/EngC only encode one property or the other. The combination of visual cues for both partial charge and hybridization appears to yield a significant increase in accuracy. Unfortunately, no scheme encoding just partial charge and hybridization was included in the AugChemception study.</p>
<p>Perhaps the most interesting finding of the AugChemception study was the one involving RedA. This schema only encodes atom positions with a uniform grayscale value of 1. In other words, these images consist of nothing more than uniformly shaded points representing the relative positions of atoms laid out on a 2D coordinate system.</p>
<p>Referring back to Figure 3, which records accuracies against Tox21, RedA produces about 72% AUC. While this is significantly below the original Chemception Std schema, it is well above the 0.5 AUC for random noise. Although RedA performed much more poorly against the other two datasets, its performance in Tox21 demonstrates that images carrying no chemical information other than 2D atom layout can produce models much more accurate than noise and within the range of more chemically-rich schemas.</p>
<p>As the authors note:</p>
<blockquote>
<p>These results suggest that explicit knowledge of bonds was apparently not the most important requirement for determining molecular toxicity. Given how fundamentally important the concept of chemical bonds is in chemistry, at first glance this observation is paradoxical. However, one has to recall that a bond is an artificial construct introduced to denote the linkages between various atoms, and one of its key role in chemistry research is to make it easier for chemists to formulate more sophisticated concepts starting with the notion of a bond.</p>
</blockquote>
<p>The best AugChemception schema was then compared with reported model building systems. The results show AugChemception to be competitive across the board.</p>
<p><a href="https://arxiv.org/abs/1710.02238" target="_blank">
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/images/posts/20190204/augchemception-benchmark.png" alt="AugChemception Benchmark" />
      <figcaption>AugChemception Benchmark</figcaption>
    </figure>
</a></p>


<h1 class="relative group">Whither Fingerprints? 
    <div id="whither-fingerprints" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#whither-fingerprints" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>Chemception offers a compelling demonstration of the power of CNNs to extract chemically-meaningful features with very little human guidance. However, it&rsquo;s not alone. Within the last two years, at least two other deep learning systems have been reported that forgo molecular fingerprints for more direct graph representations:</p>
<ul>
<li><a href="https://arxiv.org/abs/1603.00856" target="_blank">ConvGraph</a>. Implements convolutional layers designed for use on graph representations directly.</li>
<li><a href="https://doi.org/10.1021/acscentsci.7b00572" target="_blank">Continuous Representations from SMILES</a>. Maps an arbitrary raw SMILE string to a coordinate in continuous &ldquo;latent space.&rdquo; After translation by some distance, the new point can be decoded to a new molecular representation.</li>
</ul>
<p>Given the novelty of these fingerprint-free approaches and large space for optimization, it seems likely that systems based on this new paradigm will continue to advance and may one day begin to consistently outperform fingerprint-based methods.</p>


<h1 class="relative group">Hands-On Practice 
    <div id="hands-on-practice" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#hands-on-practice" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>A <a href="https://www.wildcardconsulting.dk/useful-information/learn-how-to-teach-your-computer-to-see-chemistry-free-chemception-models-with-rdkit-and-keras/" target="_blank">recent tutorial</a> by Esben Bjerrum reported a detailed, step-by-step procedure for creating and training an AugChemception network with open source tools.</p>
<p>In addition to source code and package assembly instructions, Bjerrum&rsquo;s tutorial depicts examples of AugChemception images. For example, the following image illustrates variable bond shading and atom colorings:</p>
<!-- raw HTML omitted -->
<p>CNNs offer the capability to peek into various layers by examining the filters or &ldquo;kernels&rdquo; being used. The following example from layer 15 gives an idea of the features being detected by Chemception:</p>
<!-- raw HTML omitted -->


<h1 class="relative group">Conclusion 
    <div id="conclusion" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#conclusion" aria-label="Anchor">#</a>
    </span>        
    
</h1>
<p>I doubt that the current accuracy of Chemception&rsquo;s predictions would be of practical use today. Rather, Chemception provides a platform from which such systems may eventually emerge. Recent history suggests that such an emergence may be closer than it seems.</p>
<p>Chemception offers a glimpse into a future in which lightly processed chemical datasets can be fed directly into off-the-shelf data learning pipelines to yield highly accurate predictive models. In this future, an iteratively hand-crafted molecular representation is no longer necessary. Instead, the system adapts itself to a much more raw form of structural data, identifying and classifying molecular features on its own and in a matter that may significantly diverge from human intuition.</p>
<p>Chemception also hints at the potential for deepening insights into numerous kinds of structure-property relationships. Already it&rsquo;s clear that some predictions will be more amenable to this streamlined approach than others. Could, for example, well-suited problems have some deeper, as yet unidentified, physical connection? Investigations along these lines may be aided by probing the convolutional layers generated during training.</p>
<p>Finally, it&rsquo;s worth mentioning the uncanny way in which Chemception seems to operate. For many chemists, and medicinal chemists in particular, 2D structure images are the bread-and-butter for the work they do. Structure images are information-rich, readily parsed, and instantly recognizable. They are the go-to resource for just about any project focused on getting small organic molecules to do something useful. The fact that Chemception is using a nearly identical form of input to perform what is essentially the same task as many highly-trained chemists is&hellip; unsettling.</p>
<p>It&rsquo;s one thing for a neural network to beat the pants off of someone classifying cat pictures or playing Go. It&rsquo;s an entirely different matter to ponder a neural network that routinely surpasses the world&rsquo;s best medicinal chemists.</p>

          
          
          
        </div>
        
        

        
        

          
      </div>
     
      
      
        
        
          
          
        
      <script>
        var oid = "views_posts\/2019-02-04-chemception-deep-learning-from-2d-chemical-structure-images.md"
        var oid_likes = "likes_posts\/2019-02-04-chemception-deep-learning-from-2d-chemical-structure-images.md"
      </script>
      
      
      <script type="text/javascript" src="/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js" integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q&#43;oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script>
      
  
    </section>
  <footer class="pt-8 max-w-prose print:hidden">

    
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group mr-3" href="/articles/2019/01/28/the-nextmove-patent-reaction-dataset/">
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >The NextMove Patent Reaction Dataset</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2019-01-28T14:30:00&#43;00:00">January 28, 2019</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="flex text-right group ml-3" href="/articles/2019/02/11/distributed-chemistry/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Distributed Chemistry</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2019-02-11T23:00:00&#43;00:00">February 11, 2019</time>
                  
                </span>
              </span>
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
            </a>
          
        </span>
      </div>
    </div>
  


    
  </footer>
</article>

      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top" title="Scroll to top">
    &uarr;
  </a>
</div>
    </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
  
  <div class="flex items-center justify-between">

    
    
    <p class="text-sm text-neutral-500 dark:text-neutral-400">
      &copy;
      2024
      
    </p>
    

    
    
    <p class="text-xs text-neutral-500 dark:text-neutral-400">
      
      
      Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://blowfish.page/" target="_blank" rel="noopener noreferrer">Blowfish</a>
    </p>
    

  </div>
  <script>
    
    mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
      margin: 24,
      background: 'rgba(0,0,0,0.5)',
      scrollOffset: 0,
    })
    
  </script>
  
  
  <script type="text/javascript" src="/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js" integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

</html>
