<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Big Data in Chemistry: Mirroring PubChem the Easy Way Part 2 | Depth-First</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="One of the useful (and unnerving) things about running a blog is that you&rsquo;re forced to face what you don&rsquo;t know (usually very publicly). I&rsquo;ve been looking for the simplest way to maintain an up-to-date local copy of PubChem. I previously posted an article describing one way to mirror PubChem through the use of rsync and curlftpfs.
Although this method works, it turns out that there&rsquo;s an even simpler way to do this with wget. For Compounds:">
    <meta name="generator" content="Hugo 0.139.4">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/articles/2010/02/09/big-data-in-chemistry-mirroring-pubchem-the-easy-way-part-2/">
    

    <meta property="og:url" content="http://localhost:1313/articles/2010/02/09/big-data-in-chemistry-mirroring-pubchem-the-easy-way-part-2/">
  <meta property="og:site_name" content="Depth-First">
  <meta property="og:title" content="Big Data in Chemistry: Mirroring PubChem the Easy Way Part 2">
  <meta property="og:description" content="One of the useful (and unnerving) things about running a blog is that you’re forced to face what you don’t know (usually very publicly). I’ve been looking for the simplest way to maintain an up-to-date local copy of PubChem. I previously posted an article describing one way to mirror PubChem through the use of rsync and curlftpfs.
Although this method works, it turns out that there’s an even simpler way to do this with wget. For Compounds:">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2010-02-09T00:00:00+00:00">
    <meta property="article:modified_time" content="2010-02-09T00:00:00+00:00">

  <meta itemprop="name" content="Big Data in Chemistry: Mirroring PubChem the Easy Way Part 2">
  <meta itemprop="description" content="One of the useful (and unnerving) things about running a blog is that you’re forced to face what you don’t know (usually very publicly). I’ve been looking for the simplest way to maintain an up-to-date local copy of PubChem. I previously posted an article describing one way to mirror PubChem through the use of rsync and curlftpfs.
Although this method works, it turns out that there’s an even simpler way to do this with wget. For Compounds:">
  <meta itemprop="datePublished" content="2010-02-09T00:00:00+00:00">
  <meta itemprop="dateModified" content="2010-02-09T00:00:00+00:00">
  <meta itemprop="wordCount" content="233">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Big Data in Chemistry: Mirroring PubChem the Easy Way Part 2">
  <meta name="twitter:description" content="One of the useful (and unnerving) things about running a blog is that you’re forced to face what you don’t know (usually very publicly). I’ve been looking for the simplest way to maintain an up-to-date local copy of PubChem. I previously posted an article describing one way to mirror PubChem through the use of rsync and curlftpfs.
Although this method works, it turns out that there’s an even simpler way to do this with wget. For Compounds:">

	
  </head><body class="ma0 avenir bg-near-white development">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Depth-First
      
    </a>
    <div class="flex-l items-center">
      

      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Articles
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">Big Data in Chemistry: Mirroring PubChem the Easy Way Part 2</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2010-02-09T00:00:00Z">February 9, 2010</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>One of the useful (and unnerving) things about running a blog is that you&rsquo;re forced to face what you don&rsquo;t know (usually very publicly). I&rsquo;ve been looking for the simplest way to maintain an up-to-date local copy of PubChem. I previously posted an article describing one way to <a href="http://depth-first.com/articles/2010/02/08/big-data-in-chemistry-mirroring-pubchem-the-easy-way">mirror PubChem</a> through the use of rsync and curlftpfs.</p>
<p>Although this method works, it turns out that there&rsquo;s an even simpler way to do this with wget. For Compounds:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget --mirror --accept <span style="color:#e6db74">&#34;*.sdf.gz&#34;</span> ftp://ftp.ncbi.nlm.nih.gov/pubchem/Compound/CURRENT-Full/SDF/
</span></span></code></pre></div><p>For Substances:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget --mirror --accept <span style="color:#e6db74">&#34;*.sdf.gz&#34;</span> ftp://ftp.ncbi.nlm.nih.gov/pubchem/Substance/CURRENT-Full/SDF/
</span></span></code></pre></div><p>The &ndash;mirror option bundles several options together relating to <!-- raw HTML omitted -->timestamping<!-- raw HTML omitted -->. This is how wget will be able to download only the updates to the PubChem archives directory, rather than downloading the entire PubChem archive every time.</p>
<p>Without any options, the default behavior of wget is to not preserve timestamps and to force a complete download of all files every time.</p>
<p>The <code>--accept</code> option says we only want to download gzipped SDF files (leaving out, for example, text files).</p>
<p>Whenever you&rsquo;re ready to update your local PubChem archive, simple run the two commands above and you&rsquo;re done. You&rsquo;ll have a copy of the PubChem dataset that matches - to within one day - the dataset being used by NCBI itself.</p>
<p>Pretty simple, huh?</p>
<p>Now if I could just figure out how to use a single wget command to mirror both the Compound and Substance directories&hellip;</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  Depth-First 2024 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
